Nice — I’ll give you a **ready-to-drop, production-ready JS choreography plan** that ties Acts II’s three puzzles into one fluid, cinematic experience using **Three.js + GSAP + WebAudio**. It’s a single-file, modular pattern you can expand, instrumented for performance, mobile fallbacks, accessibility, and secure server submission hooks.

What you’ll get below:

* A single ES module (`act2-stage.js`) that initializes the Three.js stage, WebAudio, and GSAP timelines.
* Modular puzzle controllers: `choreographer`, `gallery`, `dialogue`.
* Deterministic seeding for daily variance.
* Clear integration points for puzzle-complete hooks and server submission (`/api/submit-answer`).
* Mobile battery & WebGL fallback handling.
* Comments, tip notes, and minimal CSS hints.

Drop this file into your front-end bundle (Vite/Parcel/Webpack) and adapt assets/audio URLs and your API endpoints.

---

### How to use

1. Install dependencies: `three` and `gsap`.
   `npm install three gsap`
2. Place `act2-stage.js` in your front-end project and import in the page that runs Act II:

   ```js
   import { initAct2 } from './act2-stage.js';
   initAct2(document.getElementById('act2-root'), { visitorId, seed, apiBase: '/api' });
   ```
3. Provide small audio stems in `/assets/audio/` or update `AUDIO_URLS`.
4. Ensure your API endpoint `/api/submit-answer` accepts JSON POSTs (the file uses a secure Lambda endpoint in production).

---

### The file: `act2-stage.js`

```js
// act2-stage.js
// ES module: Three.js + GSAP choreography for Act II (The Becoming).
// Minimal external dependencies: three, gsap
// Usage: import { initAct2 } from './act2-stage.js'; initAct2(containerEl, { visitorId, seed, apiBase });

import * as THREE from 'three';
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js'; // optional if you add models later
import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls.js';
import { gsap } from 'gsap';

/* --------------------------
   Configuration & constants
   -------------------------- */
const AUDIO_URLS = {
  pad: '/assets/audio/act2-pad.mp3',     // ambient pad
  motif: '/assets/audio/act2-motif.mp3', // motif stems
  chord: '/assets/audio/piano-chord.mp3' // short chord for puzzle success
};

const DEFAULTS = {
  particleCount: 800,
  mobileParticleCount: 220,
  baseColor: 0x0f0722, // deep indigo
  accentColor: 0xffcc77, // gold
  bloomStrength: 0.9, // used if you add postprocessing
};

const TOUCH_TIMEOUT = 400; // ms for distinguishing gestures

/* --------------------------
   Helpers - seed and utils
   -------------------------- */
function simpleSeedHash(...parts) {
  const s = parts.join('|');
  let h = 2166136261 >>> 0;
  for (let i = 0; i < s.length; i++) {
    h = Math.imul(h ^ s.charCodeAt(i), 16777619) >>> 0;
  }
  return h;
}
function pickFromSeed(seed, arr) { return arr[seed % arr.length]; }
function clamp(v, a, b) { return Math.max(a, Math.min(b, v)); }

/* --------------------------
   Stage initializer
   -------------------------- */
export async function initAct2(container, opts = {}) {
  if (!container) throw new Error('container element required');

  // Options
  const visitorId = opts.visitorId || localStorage.getItem('visitorId') || (Math.random().toString(36).slice(2));
  const seed = opts.seed || simpleSeedHash((new Date()).toISOString().slice(0,10), visitorId);
  const apiBase = opts.apiBase || '';

  const isMobile = /Mobi|Android/i.test(navigator.userAgent);
  const particleCount = isMobile ? DEFAULTS.mobileParticleCount : DEFAULTS.particleCount;

  // Create UI scaffolding
  container.classList.add('act2-root');
  container.innerHTML = `
    <div class="act2-canvas-wrap" aria-hidden="false"></div>
    <div class="act2-ui" aria-live="polite" role="status"></div>
  `;
  const canvasWrap = container.querySelector('.act2-canvas-wrap');
  const uiWrap = container.querySelector('.act2-ui');

  // Basic CSS hints (you can move to your CSS file)
  const style = document.createElement('style');
  style.textContent = `
    .act2-root { position: relative; width: 100%; height: 100vh; overflow: hidden; background: radial-gradient(circle at 20% 10%, #11021b, #05010a); }
    .act2-canvas-wrap { position: absolute; inset: 0; }
    .act2-ui { position: absolute; left: 20px; right: 20px; top: 18px; z-index: 30; pointer-events: none; font-family: 'Georgia', serif; color: rgba(255,255,255,0.95); text-shadow: 0 6px 30px rgba(0,0,0,0.6); }
    .act2-hint { pointer-events: auto; background: rgba(0,0,0,0.35); padding: 8px 12px; display: inline-block; border-radius: 10px; backdrop-filter: blur(6px); cursor: pointer; }
  `;
  document.head.appendChild(style);

  /* --------------------------
     Three.js Scene Setup
     -------------------------- */
  const scene = new THREE.Scene();
  scene.fog = new THREE.FogExp2(DEFAULTS.baseColor, 0.02);

  const camera = new THREE.PerspectiveCamera(50, canvasWrap.clientWidth / canvasWrap.clientHeight, 0.1, 2000);
  camera.position.set(0, 1.6, 4);

  const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
  renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
  renderer.setSize(canvasWrap.clientWidth, canvasWrap.clientHeight);
  renderer.outputEncoding = THREE.sRGBEncoding;
  canvasWrap.appendChild(renderer.domElement);

  // Controls (gentle)
  const controls = new OrbitControls(camera, renderer.domElement);
  controls.enablePan = false;
  controls.enableZoom = false;
  controls.enableDamping = true;
  controls.minPolarAngle = 0.7;
  controls.maxPolarAngle = 2.0;

  // Lights
  const hemi = new THREE.HemisphereLight(0xffffee, 0x222233, 0.25);
  scene.add(hemi);
  const key = new THREE.PointLight(DEFAULTS.accentColor, 1.2, 12, 2);
  key.position.set(0, 3, 2);
  scene.add(key);

  // Add a subtle stage floor (reflective shader can be added later)
  const floorGeo = new THREE.PlaneGeometry(40, 40);
  const floorMat = new THREE.MeshStandardMaterial({ color: 0x06030a, roughness: 0.8, metalness: 0.1 });
  const floor = new THREE.Mesh(floorGeo, floorMat);
  floor.rotation.x = -Math.PI / 2;
  floor.position.y = -0.9;
  scene.add(floor);

  /* --------------------------
     Particles & silhouette dancer (shared)
     -------------------------- */
  // Particle field used by several puzzles (ribbon trails & ambient)
  const particlesGeo = new THREE.BufferGeometry();
  const pos = new Float32Array(particleCount * 3);
  for (let i = 0; i < particleCount; i++) {
    pos[3*i] = (Math.random() - 0.5) * 12;
    pos[3*i+1] = (Math.random() * 2) - 0.6;
    pos[3*i+2] = (Math.random() - 0.5) * 6;
  }
  particlesGeo.setAttribute('position', new THREE.BufferAttribute(pos, 3));
  const particlesMat = new THREE.PointsMaterial({ size: isMobile ? 0.03 : 0.06, color: DEFAULTS.accentColor, transparent: true, opacity: 0.85, depthWrite: false, blending: THREE.AdditiveBlending });
  const particles = new THREE.Points(particlesGeo, particlesMat);
  scene.add(particles);

  // Simple silhouette using a tinted plane with alpha gradient (cheap)
  const silhouetteGeo = new THREE.PlaneGeometry(1.2, 2.1, 8, 8);
  const silhouetteMat = new THREE.MeshBasicMaterial({ color: 0x111111, transparent: true, opacity: 0.0, blending: THREE.AdditiveBlending });
  const silhouette = new THREE.Mesh(silhouetteGeo, silhouetteMat);
  silhouette.position.set(0, 0.6, -0.5);
  silhouette.scale.set(1.2, 1.2, 1.2);
  scene.add(silhouette);

  /* --------------------------
     WebAudio minimal setup
     -------------------------- */
  const AudioContext = window.AudioContext || window.webkitAudioContext;
  const audioCtx = new AudioContext();
  const masterGain = audioCtx.createGain();
  masterGain.gain.value = 0.9;
  masterGain.connect(audioCtx.destination);

  async function loadAudioBuffer(url) {
    try {
      const res = await fetch(url);
      const ab = await res.arrayBuffer();
      return await audioCtx.decodeAudioData(ab);
    } catch (err) {
      console.warn('Audio load fail', url, err);
      return null;
    }
  }
  // Preload small stems
  const [padBuf, motifBuf, chordBuf] = await Promise.all([AUDIO_URLS.pad, AUDIO_URLS.motif, AUDIO_URLS.chord].map(loadAudioBuffer));
  const audio = { padBuf, motifBuf, chordBuf };

  function playBuffer(buf, when = 0, opts = {}) {
    if (!buf) return null;
    const src = audioCtx.createBufferSource();
    src.buffer = buf;
    const g = audioCtx.createGain();
    g.gain.value = (typeof opts.gain === 'number') ? opts.gain : 0.5;
    src.connect(g);
    g.connect(masterGain);
    src.start(audioCtx.currentTime + when);
    return { src, gainNode: g };
  }

  // Start ambient pad (looped)
  let padNode = null;
  if (audio.padBuf) {
    padNode = audioCtx.createBufferSource();
    padNode.buffer = audio.padBuf;
    padNode.loop = true;
    const g = audioCtx.createGain();
    g.gain.value = 0.18;
    padNode.connect(g);
    g.connect(masterGain);
    padNode.start();
  }

  /* --------------------------
     Interaction & responsive helpers
     -------------------------- */
  let lastTouchTime = 0;
  canvasWrap.addEventListener('touchstart', () => { lastTouchTime = Date.now(); }, { passive: true });

  let pointer = { x: 0, y: 0, nx: 0, ny: 0, down: false };
  function updatePointer(event) {
    const rect = renderer.domElement.getBoundingClientRect();
    const clientX = event.touches ? event.touches[0].clientX : event.clientX;
    const clientY = event.touches ? event.touches[0].clientY : event.clientY;
    pointer.x = (clientX - rect.left) / rect.width;
    pointer.y = (clientY - rect.top) / rect.height;
    pointer.nx = (pointer.x - 0.5) * 2;
    pointer.ny = - (pointer.y - 0.5) * 2;
  }
  renderer.domElement.addEventListener('pointermove', (e) => { updatePointer(e); });
  renderer.domElement.addEventListener('pointerdown', (e) => { pointer.down = true; updatePointer(e); });
  window.addEventListener('pointerup', () => { pointer.down = false; });

  /* --------------------------
     Puzzle Modules (choreographer, gallery, dialogue)
     Each returns an object:
       { start(), stop(), update(), onComplete(callback) }
     -------------------------- */

  // -- Puzzle 4: The Choreographer --
  function createChoreographer(seed) {
    const local = {};
    local.completed = false;
    local.requiredPoses = 3;
    local.matched = 0;
    local.poseTemplates = generatePoses(seed, local.requiredPoses);

    // ribbon trail geometry
    const trailGeo = new THREE.BufferGeometry();
    const maxTrail = 120;
    const trailPos = new Float32Array(maxTrail * 3);
    trailGeo.setAttribute('position', new THREE.BufferAttribute(trailPos, 3));
    const trailMat = new THREE.PointsMaterial({ size: 0.06, color: DEFAULTS.accentColor, transparent: true, opacity: 0.85, blending: THREE.AdditiveBlending });
    const trail = new THREE.Points(trailGeo, trailMat);
    scene.add(trail);

    // small shimmer to indicate active target
    const targetMat = new THREE.MeshBasicMaterial({ color: DEFAULTS.accentColor, transparent: true, opacity: 0.0 });
    const targetMesh = new THREE.Mesh(new THREE.SphereGeometry(0.08, 8, 8), targetMat);
    scene.add(targetMesh);

    // Pose matching heuristic: she must sweep through three regions in order
    let currentPoseIndex = 0;
    let trailIndex = 0;

    function generatePoses(seed, count) {
      const poses = [];
      for (let i = 0; i < count; i++) {
        const angle = ((seed >>> (i*3)) % 360) * (Math.PI/180);
        const r = 0.8 + Math.abs(Math.sin(angle)) * 1.6;
        // positions in world space
        poses.push(new THREE.Vector3(Math.cos(angle) * r, 0.6 + (i*0.12), Math.sin(angle) * 0.6 - 0.3));
      }
      return poses;
    }

    // Visualize pose targets (subtle)
    const poseDots = local.poseTemplates.map(p => {
      const mat = new THREE.MeshBasicMaterial({ color: 0xffddbb, transparent: true, opacity: 0.12 });
      const m = new THREE.Mesh(new THREE.SphereGeometry(0.06, 8, 8), mat);
      m.position.copy(p);
      scene.add(m);
      return m;
    });

    let onCompleteCb = ()=>{};
    function start() {
      // animate entrance: fade in silhouette and particles
      gsap.fromTo(silhouette.material, { opacity: 0.0 }, { opacity: 0.92, duration: 1.1, ease: 'power2.out' });
      gsap.fromTo(particles.material, { opacity: 0.0 }, { opacity: 0.85, duration: 1.2 });
      // reset
      local.matched = 0;
      currentPoseIndex = 0;
      poseDots.forEach((d, i) => { d.material.opacity = 0.12; d.scale.set(1,1,1); });
    }
    function stop() {
      gsap.to(silhouette.material, { opacity: 0.0, duration: 0.6 });
    }

    function update(dt) {
      // update ribbon trail: insert pointer world position
      const worldX = pointer.nx * 2.4;
      const worldY = clamp(1.2 + pointer.ny * 0.9, -0.2, 2.2);
      const worldZ = -0.5 + (pointer.nx * -0.2);

      // shift positions down the buffer
      for (let i = (trailPos.length/3 - 1); i > 0; i--) {
        trailPos[3*i] = trailPos[3*(i-1)];
        trailPos[3*i+1] = trailPos[3*(i-1)+1];
        trailPos[3*i+2] = trailPos[3*(i-1)+2];
      }
      trailPos[0] = worldX; trailPos[1] = worldY; trailPos[2] = worldZ;
      trailGeo.attributes.position.needsUpdate = true;

      // silhouette follows with a delay (mirror)
      silhouette.position.x += (worldX - silhouette.position.x) * 0.08;
      silhouette.position.y += (worldY - silhouette.position.y) * 0.06;
      silhouette.rotation.z = pointer.nx * 0.08;

      // check pose proximity
      if (currentPoseIndex < local.poseTemplates.length && pointer.down) {
        const target = local.poseTemplates[currentPoseIndex];
        const dist = Math.hypot(worldX - target.x, worldY - target.y);
        // visual hint
        const dot = poseDots[currentPoseIndex];
        dot.material.opacity = clamp(0.4 - dist*0.55, 0.04, 0.7);
        dot.scale.setScalar(clamp(1.0 + (0.6 - dist)*0.9, 0.8, 1.8));
        if (dist < 0.35) {
          // matched pose
          gsap.to(dot.material, { opacity: 0.95, duration: 0.25 });
          currentPoseIndex++;
          local.matched++;
          // play motif chord
          playBuffer(audio.motifBuf, 0, { gain: 0.38 });

          if (local.matched >= local.requiredPoses) {
            local.completed = true;
            // celebration animation
            gsap.to(trail.material, { opacity: 0.2, duration: 1.2 });
            gsap.to(silhouette.material, { opacity: 0.0, duration: 1.3 });
            // play chord and call onComplete
            playBuffer(audio.chordBuf, 0, { gain: 0.9 });
            setTimeout(()=> onCompleteCb({ puzzleId: 'choreographer' }), 800);
          }
        }
      } else {
        // subtle pulse to indicate waiting
        const idx = currentPoseIndex % poseDots.length;
        gsap.to(poseDots[idx].material, { opacity: 0.12 + Math.abs(Math.sin(Date.now()*0.001))*0.06, duration: 0.8 });
      }
    }

    function onComplete(cb) { onCompleteCb = cb; }

    return { start, stop, update, onComplete, completed: () => local.completed };
  }

  // -- Puzzle 5: Gallery of Us (shader canvases)
  function createGallery(seed) {
    const local = {};
    local.completed = false;
    local.frames = [];
    const frameCount = 5;
    let onCompleteCb = ()=>{};

    // Create shader-like planes with animated noise uniforms
    const frag = `
      uniform float uTime;
      uniform vec3 uColorA;
      uniform vec3 uColorB;
      varying vec2 vUv;
      // Simple noise function (value noise)
      float hash(vec2 p) { return fract(sin(dot(p,vec2(127.1,311.7))) * 43758.5453123); }
      float noise(vec2 p){
        vec2 i = floor(p);
        vec2 f = fract(p);
        float a = hash(i);
        float b = hash(i + vec2(1.0, 0.0));
        float c = hash(i + vec2(0.0, 1.0));
        float d = hash(i + vec2(1.0, 1.0));
        vec2 u = f*f*(3.0-2.0*f);
        return mix(a, b, u.x) + (c - a)*u.y*(1.0 - u.x) + (d - b)*u.x*u.y;
      }
      void main() {
        vec2 uv = vUv * 2.0 - 1.0;
        float n = noise(uv * 3.0 + uTime * 0.2);
        float t = smoothstep(0.1, 0.6, n);
        vec3 col = mix(uColorA, uColorB, t);
        gl_FragColor = vec4(col, 1.0);
      }
    `;
    const vert = `
      varying vec2 vUv;
      void main() {
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    `;

    for (let i = 0; i < frameCount; i++) {
      const mat = new THREE.ShaderMaterial({
        uniforms: {
          uTime: { value: Math.random()*10 },
          uColorA: { value: new THREE.Color(0x1b0f2a) },
          uColorB: { value: new THREE.Color(0x6b2c56) }
        },
        vertexShader: vert,
        fragmentShader: frag,
      });
      const mesh = new THREE.Mesh(new THREE.PlaneGeometry(1.1, 1.6), mat);
      mesh.position.set(-2 + i*1.0, 0.4 + Math.sin(i)*0.06, -1 - Math.abs(i-2)*0.2);
      mesh.userData = { idx: i, hovered: false, clarified: false };
      scene.add(mesh);
      local.frames.push(mesh);
    }

    function start() {
      // entrance
      gsap.from(local.frames.map(f=>f.position), { y: '+=0.35', stagger: 0.08, duration: 0.9, ease: 'power2.out' });
    }
    function stop() { /* optional elegant exit */ }
    function update(dt) {
      // update shader times
      local.frames.forEach((m, i) => {
        m.material.uniforms.uTime.value += dt * 0.6 * (0.9 + i*0.04);
        // proximity effect (pointer->mesh)
        // compute pointer world intersection against plane approx:
        const worldX = pointer.nx * 2.2;
        const worldY = 0.9 + pointer.ny * 0.9;
        const dist = Math.hypot(worldX - m.position.x, worldY - m.position.y);
        if (dist < 0.7 && !m.userData.clarified && pointer.down) {
          // clarify: animate color towards lighter tone
          m.userData.clarified = true;
          gsap.to(m.material.uniforms.uColorA.value, { r: 0.9, g: 0.78, b: 0.64, duration: 1.2 });
          gsap.to(m.material.uniforms.uColorB.value, { r: 0.98, g: 0.84, b: 0.56, duration: 1.2 });
          // small audio flourish
          playBuffer(audio.motifBuf, 0, { gain: 0.25 });
          // if majority clarified, complete
          const clarifiedCount = local.frames.filter(x=>x.userData.clarified).length;
          if (clarifiedCount >= Math.ceil(local.frames.length * 0.6)) {
            local.completed = true;
            // merge colors into single sphere
            const sphere = new THREE.Mesh(new THREE.SphereGeometry(0.4, 24, 24), new THREE.MeshBasicMaterial({ color: 0xffdba6, transparent: true, opacity: 0.0 }));
            sphere.position.set(0, 1.2, -0.9);
            scene.add(sphere);
            gsap.to(sphere.material, { opacity: 1.0, duration: 0.9 });
            gsap.to(sphere.scale, { x: 1.27, y: 1.27, z: 1.27, duration: 0.9, ease: 'elastic.out(1,0.6)' });
            playBuffer(audio.chordBuf, 0, { gain: 0.9 });
            setTimeout(()=>onCompleteCb({ puzzleId: 'gallery' }), 900);
          }
        }
      });
    }
    function onComplete(cb) { onCompleteCb = cb; }
    return { start, stop, update, onComplete, completed: () => local.completed };
  }

  // -- Puzzle 6: Dialogue (interactive text) --
  function createDialogue(seed) {
    const local = {};
    local.completed = false;
    let onCompleteCb = ()=>{};
    const prompts = [
      { id: 'q1', text: 'Coincidence or choreography?', choices: ['Coincidence', 'Choreography', 'Both'] },
      { id: 'q2', text: 'Do you prefer the quiet backstage or the bright stage?', choices: ['Backstage', 'Stage', 'Both'] },
      { id: 'q3', text: 'Is love a rehearsal or a performance?', choices: ['Rehearsal', 'Performance', 'Both'] },
    ];
    let index = 0;
    const results = [];

    // UI overlay for questions (HTML)
    const dialogEl = document.createElement('div');
    dialogEl.className = 'act2-dialog';
    dialogEl.style.position = 'absolute';
    dialogEl.style.bottom = '36px';
    dialogEl.style.left = '50%';
    dialogEl.style.transform = 'translateX(-50%)';
    dialogEl.style.pointerEvents = 'auto';
    dialogEl.style.zIndex = 40;
    dialogEl.style.textAlign = 'center';
    uiWrap.appendChild(dialogEl);

    function renderPrompt() {
      dialogEl.innerHTML = '';
      const p = prompts[index];
      const q = document.createElement('div');
      q.style.margin = '8px 0 10px';
      q.style.fontSize = '20px';
      q.style.opacity = '0';
      q.textContent = p.text;
      dialogEl.appendChild(q);
      gsap.to(q, { opacity: 1, duration: 0.6 });

      const choicesWrap = document.createElement('div');
      choicesWrap.style.display = 'flex';
      choicesWrap.style.justifyContent = 'center';
      choicesWrap.style.gap = '10px';
      p.choices.forEach(choice => {
        const btn = document.createElement('button');
        btn.className = 'act2-choice';
        btn.textContent = choice;
        btn.style.padding = '8px 12px';
        btn.style.borderRadius = '8px';
        btn.style.border = 'none';
        btn.style.background = 'rgba(255,255,255,0.08)';
        btn.style.color = 'white';
        btn.style.cursor = 'pointer';
        btn.onclick = async () => {
          // local reaction: color shift and subtle sound
          playBuffer(audio.motifBuf, 0, { gain: 0.22 });
          gsap.to(document.body, { '--accent-hint': '#ffd6b3', duration: 0.12 });
          results.push({ id: p.id, choice });
          index++;
          if (index >= prompts.length) {
            // finalize
            local.completed = true;
            // small "quill" animation across screen
            const writing = document.createElement('div');
            writing.textContent = '—';
            writing.style.position = 'absolute';
            writing.style.left = '50%';
            writing.style.top = '30%';
            writing.style.transform = 'translateX(-50%)';
            writing.style.fontSize = '36px';
            writing.style.opacity = '0';
            uiWrap.appendChild(writing);
            gsap.to(writing, { opacity: 1, duration: 0.6, y: '-=8', ease: 'power2.out' });
            playBuffer(audio.chordBuf, 0, { gain: 0.75 });
            // send results to server
            submitAnswers({ visitorId, seed, answers: results, puzzleId: 'dialogue' });
            setTimeout(()=> {
              onCompleteCb({ puzzleId: 'dialogue', answers: results });
              // cleanup UI
              gsap.to(dialogEl, { opacity: 0, duration: 0.9, onComplete: ()=> dialogEl.remove() });
            }, 850);
          } else {
            // show next prompt after small delay
            gsap.to(q, { opacity: 0, duration: 0.35, onComplete: renderPrompt });
          }
        };
        choicesWrap.appendChild(btn);
      });
      dialogEl.appendChild(choicesWrap);
    }

    function start() { renderPrompt(); }
    function stop() { dialogEl.remove(); }
    function update(dt) { /* no continuous update needed */ }
    function onComplete(cb) { onCompleteCb = cb; }
    return { start, stop, update, onComplete, completed: () => local.completed };
  }

  /* --------------------------
     High-level timeline orchestration (GSAP)
     -------------------------- */
  // instantiate modules
  const choreographer = createChoreographer(seed);
  const gallery = createGallery(seed);
  const dialogue = createDialogue(seed);

  // puzzle order and gating
  const puzzleOrder = [choreographer, gallery, dialogue];
  let currentPuzzleIndex = 0;

  // progressive start -> each puzzle auto-starts after prev completes
  function startAct() {
    // resume audiocontext on user gesture (required by many browsers)
    if (audioCtx.state === 'suspended') audioCtx.resume().catch(()=>{});
    // intro cinematic: subtle fade-ins
    gsap.fromTo(camera.position, { z: 5 }, { z: 4, duration: 1.6, ease: 'power2.out' });
    // start first puzzle
    puzzleOrder[currentPuzzleIndex].start();
    puzzleOrder.forEach(p => p.onComplete(handlePuzzleComplete));
    // set UI message
    showUIMessage('Act II — The Becoming', 2200);
  }

  function handlePuzzleComplete(info) {
    // mark complete, send analytic / save
    console.log('Puzzle completed', info);
    submitProgress({ visitorId, seed, puzzleId: info.puzzleId });
    // trigger small celebratory visual
    gsap.to(key, { intensity: 1.6, duration: 0.25, yoyo: true, repeat: 1 });
    // advance
    currentPuzzleIndex++;
    if (currentPuzzleIndex < puzzleOrder.length) {
      // small transition between puzzles
      const next = puzzleOrder[currentPuzzleIndex];
      crossfadeTo(next);
      next.start();
    } else {
      // Act II finished
      showUIMessage('Act II — curtain call', 4500);
      // give final trail flourish
      playBuffer(audio.chordBuf, 0, { gain: 0.95 });
    }
  }

  function crossfadeTo(nextModule) {
    // simple camera/lighting cinematic crossfade using GSAP
    gsap.to(camera.position, { z: Math.max(3.8, camera.position.z - 0.35), duration: 0.9, ease: 'power2.out' });
    gsap.to(key.position, { y: 2.2, duration: 0.9, ease: 'power2.out' });
    // fade particles a bit
    gsap.to(particles.material, { opacity: 0.45, duration: 0.6, yoyo: true, repeat: 1 });
    // small vignette shift could be added if you use postprocessing
  }

  /* --------------------------
     Render loop
     -------------------------- */
  let last = performance.now();
  function animate(now) {
    const dt = (now - last) / 1000;
    last = now;
    // update modules
    try {
      if (puzzleOrder[currentPuzzleIndex]) puzzleOrder[currentPuzzleIndex].update(dt);
    } catch(e) { /* safe guard */ }
    controls.update();
    // subtle particle float animation
    const positions = particles.geometry.attributes.position.array;
    for (let i = 0; i < positions.length; i += 3) {
      positions[i+1] += Math.sin(now*0.001 + i) * 0.00012;
    }
    particles.geometry.attributes.position.needsUpdate = true;

    renderer.render(scene, camera);
    requestAnimationFrame(animate);
  }
  requestAnimationFrame(animate);

  // Resize
  window.addEventListener('resize', () => {
    camera.aspect = canvasWrap.clientWidth / canvasWrap.clientHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(canvasWrap.clientWidth, canvasWrap.clientHeight);
  });

  // Start Act
  startAct();

  /* --------------------------
     Server submission helpers
     -------------------------- */
  async function submitAnswers(payload) {
    // Example: POST to your Lambda endpoint; the Lambda will store to DynamoDB and forward to Web3Forms
    try {
      const res = await fetch(`${apiBase}/submit-answer`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      });
      if (!res.ok) throw new Error('submit fail');
      return await res.json();
    } catch (err) {
      console.warn('submitAnswers failed', err);
      return null;
    }
  }
  async function submitProgress(payload) {
    // keep minimal payload for progress analytics
    return submitAnswers({ type: 'progress', visitorId: visitorId, seed, ...payload });
  }

  /* --------------------------
     Small UI helpers
     -------------------------- */
  function showUIMessage(text, ms = 1800) {
    uiWrap.innerHTML = `<div class="act2-hint" role="status">${text}</div>`;
    if (ms > 0) setTimeout(()=> { uiWrap.innerHTML = ''; }, ms);
  }

  // Public shutdown function if you want to unmount
  function destroy() {
    // stop audio
    try { if (padNode) padNode.stop(); } catch(e){}
    // remove DOM
    renderer.domElement.remove();
    uiWrap.innerHTML = '';
    // cancel animations etc (optionally)
  }

  // Expose a few knobs for debugging / admin preview
  return { destroy, scene, camera, renderer };
}
```

---

## Implementation notes (important)

* **Audio autoplay**: modern browsers require a user gesture to resume `AudioContext`. The code resumes on `startAct()` but ensure user taps/attempts first; gate/entry click is ideal to trigger audio.
* **Performance**: particle count is reduced on mobile. Add device detection and cap `renderer.setPixelRatio()` to 1 for low-power devices.
* **Shaders**: the provided shader is intentionally simple (value-noise-like). Replace with richer Perlin/Curl noise shaders for painterly motion.
* **Accessibility**: provide keyboard alternatives for puzzle inputs (e.g., for puzzle 4 poses, allow arrow keys to move a cursor). Provide transcripts for audio responses in the UI.
* **Testing**: test on low-end mobile (iPhone SE / older Android) to ensure graceful fallbacks; add a CSS/SVG fallback if `WebGLRenderingContext` is missing.
* **State & Persistence**: the code uses `submitAnswers()` to post results to an API endpoint. Your Lambda should validate and store to DynamoDB and forward to Web3Forms with your access key (server-side only).
* **Secrets**: never embed Web3Forms keys or DB credentials in the browser — always route through server-side Lambdas.
* **Polish**: add `postprocessing` bloom/film to create a theater glow. Use `lerp` and `ease` for natural motion.

---

## Next steps I can deliver (pick one)

* I can **convert this into a fully working React component** (preview-ready) with dev server and local assets.
* Or I can **produce the Lambda** that will accept submissions and forward them to Web3Forms, including DynamoDB writes (TypeScript CDK-ready).
* Or I can **design the Act III choreography** in the same format when you’re satisfied with Act II.

Which do you want next?
